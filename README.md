# Veltis Data Ingestion Pipeline

> Automated pipeline for ingesting and processing French healthcare data (FINESS, HAS, IQSS)

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: Open License](https://img.shields.io/badge/License-Open%20License-green.svg)](https://www.etalab.gouv.fr/licence-ouverte-open-licence/)

## Overview

This project provides a complete data pipeline for fetching, cleaning, and normalizing French healthcare data from official open data sources. It creates a unified database of healthcare establishments with their quality metrics and certifications.

### Key Features

- **Automated Ingestion**: Fetch data from data.gouv.fr and HAS
- **Data Cleaning**: Handle messy headers, encoding issues, and missing values
- **Normalization**: Generate consistent schemas with UUIDs and linking
- **Year-by-Year**: Process historical data maintaining temporal accuracy
- **Extensible**: Modular connector architecture for adding new sources

### Data Sources

| Source | Description | Provider |
|--------|-------------|----------|
| **FINESS** | National registry of healthcare establishments (~500k records) | Minist√®re de la Sant√© |
| **HAS Certification** | Quality certifications and decisions | Haute Autorit√© de Sant√© |
| **IQSS Metrics** | Annual quality and safety indicators | Minist√®re de la Sant√© |

## Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Run ingestion (defaults to 2023, or specify year)
python scripts/run_ingestion.py --year 2024

# Process data
python scripts/run_processing.py --year 2024

# Explore results
jupyter notebook notebooks/exploration_veltis_data.ipynb
```

**Output**:
- Raw data: `data/raw/2023/`
- Processed data: `data/processed/2023/`
- 3 normalized CSV files: `etablissements.csv`, `qualifications.csv`, `health_metrics.csv`

## Project Structure

```
MVP-web-scrapping-project/
‚îú‚îÄ‚îÄ scripts/              # CLI entry points
‚îÇ   ‚îú‚îÄ‚îÄ run_ingestion.py   # Fetch raw data
‚îÇ   ‚îî‚îÄ‚îÄ run_processing.py  # Clean and normalize
‚îÇ
‚îú‚îÄ‚îÄ src/                  # Core library code
‚îÇ   ‚îú‚îÄ‚îÄ ingestion_manager.py    # Orchestrates ingestion
‚îÇ   ‚îú‚îÄ‚îÄ processing/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_cleaner.py     # Cleans and normalizes data
‚îÇ   ‚îú‚îÄ‚îÄ connectors/             # API connectors (data.gouv, HAS)
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Data schemas
‚îÇ   ‚îî‚îÄ‚îÄ config.py               # Configuration
‚îÇ
‚îú‚îÄ‚îÄ docs/                 # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ API_CONNECTORS.md  # Connector usage guide
‚îÇ   ‚îú‚îÄ‚îÄ DATA_SOURCES.md    # Data source details
‚îÇ   ‚îî‚îÄ‚îÄ USAGE.md           # Complete user guide
‚îÇ
‚îú‚îÄ‚îÄ notebooks/            # Jupyter notebooks
‚îú‚îÄ‚îÄ data/                 # Data storage (not in git)
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Downloaded files
‚îÇ   ‚îî‚îÄ‚îÄ processed/        # Cleaned and normalized files
‚îÇ
‚îî‚îÄ‚îÄ requirements.txt      # Python dependencies
```

## Documentation

üìö **[Complete Usage Guide](docs/USAGE.md)** - Installation, running, troubleshooting

üîå **[API Connectors](docs/API_CONNECTORS.md)** - How connectors work, extending

üìä **[Data Sources](docs/DATA_SOURCES.md)** - Source details, schemas, integration

üìñ **[Data Dictionary](docs/DATA_DICTIONARY.md)** - Business values, field definitions, scores

## Installation

### Requirements
- Python 3.8+
- pip

### Setup

```bash
# 1. Clone repository
git clone https://github.com/your-org/MVP-web-scrapping-project.git
cd MVP-web-scrapping-project

# 2. (Optional) Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# 3. Install dependencies
pip install -r requirements.txt
```

## Usage

### 1. Data Ingestion

Fetch raw data from official sources:

```bash
python scripts/run_ingestion.py
```

Downloads:
- FINESS establishment registry (CSV, ~160MB)
- HAS certification data (2 CSV files)
- IQSS health quality metrics (Excel)

Output: `data/raw/2023/`

### 2. Data Processing

Clean and normalize the raw data:

```bash
python scripts/run_processing.py
```

Produces:
- `etablissements.csv` - Normalized establishment data with UUIDs
- `qualifications.csv` - HAS certifications linked to establishments
- `health_metrics.csv` - IQSS metrics linked to establishments

Output: `data/processed/2023/`

### 3. Data Exploration

Open the Jupyter notebook to explore the data:

```bash
jupyter notebook notebooks/exploration_veltis_data.ipynb
```

The notebook provides:
- Automatic dependency installation
- Data loading and preview
- Basic statistics and quality checks

## Architecture

### Ingestion Flow

```
data.gouv.fr APIs
       ‚Üì
DataGouvConnector / HASConnector
       ‚Üì
IngestionManager
       ‚Üì
data/raw/{year}/
```

### Processing Flow

```
data/raw/{year}/
       ‚Üì
DataProcessor
  ‚îú‚îÄ load_clean_finess()
  ‚îú‚îÄ load_clean_has()
  ‚îî‚îÄ load_clean_health_metrics()
       ‚Üì
data/processed/{year}/
```

### Connector Architecture

All connectors inherit from `BaseConnector`:

```python
from src.connectors.base import BaseConnector

class MyConnector(BaseConnector):
    def fetch_data(self):
        # Implementation with automatic retry,
        # error handling, and logging
        pass
```

See [API_CONNECTORS.md](docs/API_CONNECTORS.md) for details.

## Data Schema

### Etablissement (Establishment)
- `vel_id` (UUID) - Internal unique ID
- `finess_et` (string) - Official FINESS code
- `siret` (string) - Business number
- `raison_sociale` (string) - Organization name
- `adresse_postale` (string) - Full address
- `code_postal` (string) - Postal code
- `categorie_etab` (string) - Category (Public/Priv√©/ESPIC)

### Qualification (Certification)
- `qua_id` (UUID) - Qualification ID
- `vel_id` (UUID) - Link to establishment
- `niveau_certification` (string) - Certification level
- `date_visite` (date) - Certification visit date
- `score_satisfaction` (float) - Satisfaction score (if available)

### Health Metrics
- `vel_id` (UUID) - Link to establishment
- Multiple score and rate columns (varies by year)
- `metric_id` (UUID) - Metric record ID
- `processed_at` (timestamp) - Processing time

## Configuration

Most users can use defaults. To customize:

1. Copy `.env.example` to `.env`
2. Edit values as needed

```bash
cp .env.example .env
# Edit .env with your preferred editor
```

See [USAGE.md](docs/USAGE.md) for configuration details.

## Extending

### Adding a New Data Source

1. Create connector in `src/connectors/my_connector.py`
2. Inherit from `BaseConnector`
3. Implement `fetch_data()` method
4. Add to `IngestionManager`
5. Add cleaning logic in `DataProcessor`

Example:

```python
# src/connectors/my_connector.py
from src.connectors.base import BaseConnector

class MyConnector(BaseConnector):
    def __init__(self, config):
        super().__init__()
        self.api_url = config.api_url
    
    def fetch_data(self):
        response = self._make_request(self.api_url)
        return response.json()
```

See [API_CONNECTORS.md](docs/API_CONNECTORS.md) for full guide.

## Troubleshooting

### Common Issues

**"Dataset not found"**
- The year's data might not be published yet
- Try an earlier year (e.g., 2022 instead of 2024)

**"Connection timeout"**
- Check internet connection
- data.gouv.fr might be temporarily unavailable
- Try again later

**"Parsing error"**
- Check file encoding (FINESS uses latin-1, HAS uses utf-8)
- Verify delimiter (all CSVs use `;` semicolon)
- Check header rows (FINESS has metadata in row 1)

See [USAGE.md - Troubleshooting](docs/USAGE.md#troubleshooting-ingestion) for more.

## Data Quality

The pipeline handles common data quality issues:

- **Encoding**: Automatic detection and conversion
- **Headers**: Skips metadata rows, normalizes column names
- **Missing values**: Graceful handling with logging
- **Type conversion**: Enforces numeric types for scores/rates
- **Linking**: Normalizes FINESS codes (zero-padding, decimal removal)

## Performance

Typical runtimes on standard hardware:

- **Ingestion**: 1-2 minutes
- **Processing**: 10-30 seconds
- **Memory**: ~2GB for full dataset

## License

This project uses data published under the **License Ouverte / Open License 2.0**:
- ‚úÖ Free use, reuse, and distribution
- ‚úÖ Commercial and non-commercial use
- ‚ÑπÔ∏è Source attribution required

License: https://www.etalab.gouv.fr/licence-ouverte-open-licence/

## Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Add tests (when available)
4. Update documentation
5. Submit a pull request

## Support

- **Documentation**: See `docs/` directory
- **Issues**: Open a GitHub issue
- **Data Questions**: Contact data providers via data.gouv.fr

## Acknowledgments

Data sources:
- **Minist√®re de la Sant√© et de la Pr√©vention** - FINESS and IQSS data
- **Haute Autorit√© de Sant√© (HAS)** - Certification data
- **data.gouv.fr** - Open data platform

## Roadmap

- [ ] Unit tests for connectors and processing
- [ ] Additional years (2021-2024)
- [ ] Database export (PostgreSQL/SQLite)
- [ ] API for querying processed data
- [ ] Automated scheduling (cron/airflow)
- [ ] Data quality reporting

---

**Questions?** See [docs/USAGE.md](docs/USAGE.md) or open an issue.
