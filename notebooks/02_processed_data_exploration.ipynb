{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85065a6a",
   "metadata": {},
   "source": [
    "# Veltis Processed Data Exploration (2023)\n",
    "\n",
    "This notebook explores the cleaned and processed data in `data/processed/2023`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ba50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "YEAR = 2023\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Libraries loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657855cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Paths\n",
    "project_root = Path.cwd()\n",
    "if project_root.name == 'notebooks':\n",
    "    project_root = project_root.parent\n",
    "\n",
    "processed_dir = project_root / 'data' / 'processed' / str(YEAR)\n",
    "print(f\"Processed {YEAR} Data Path: {processed_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dedf5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Etablissements\n",
    "etab_path = processed_dir / 'etablissements.csv'\n",
    "if etab_path.exists():\n",
    "    print(f\"Loading {etab_path.name}...\")\n",
    "    df_etab = pd.read_csv(etab_path, low_memory=False)\n",
    "    print(f\"Shape: {df_etab.shape}\")\n",
    "    display(df_etab.head())\n",
    "else:\n",
    "    print(f\"File not found: {etab_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37ccb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Qualifications\n",
    "# This table contains HAS certification data.\n",
    "# Note: Health Metric scores are NOT included here (see Health Metrics below).\n",
    "qual_path = processed_dir / 'qualifications.csv'\n",
    "if qual_path.exists():\n",
    "    print(f\"Loading {qual_path.name}...\")\n",
    "    df_qual = pd.read_csv(qual_path)\n",
    "    print(f\"Shape: {df_qual.shape}\")\n",
    "    \n",
    "    # Verify columns\n",
    "    print(\"\\nColumns:\", list(df_qual.columns))\n",
    "    \n",
    "    # Check url_rapport presence\n",
    "    if 'url_rapport' in df_qual.columns:\n",
    "        print(\"\\nSample Report URLs:\")\n",
    "        print(df_qual['url_rapport'].dropna().head().values)\n",
    "        \n",
    "    display(df_qual.head())\n",
    "else:\n",
    "    print(f\"File not found: {qual_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load Health Metrics\n",
    "# This table contains IQSS quality indicators.\n",
    "# Values should be clean (e.g., 'Oui' instead of '1- Oui').\n",
    "metrics_path = processed_dir / 'health_metrics.csv'\n",
    "if metrics_path.exists():\n",
    "    print(f\"Loading {metrics_path.name}...\")\n",
    "    df_metrics = pd.read_csv(metrics_path)\n",
    "    print(f\"Shape: {df_metrics.shape}\")\n",
    "    \n",
    "    # Verify clean categorical values\n",
    "    for col in ['participation', 'depot', 'evolution']:\n",
    "        if col in df_metrics.columns:\n",
    "            print(f\"\\nValue Counts for {col}:\")\n",
    "            print(df_metrics[col].value_counts().head())\n",
    "\n",
    "    display(df_metrics.head())\n",
    "else:\n",
    "    print(f\"File not found: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Analysis: Merging Data\n",
    "# Example: Creating a unified view of Qualifications and Health Metrics\n",
    "# We can join on 'vel_id' (internal ID) or 'finess_et' (if we link back).\n",
    "\n",
    "if 'df_qual' in locals() and 'df_metrics' in locals() and 'df_etab' in locals():\n",
    "    print(\"Creating unified analysis view...\")\n",
    "    \n",
    "    # Start with Etablissements to get names\n",
    "    df_analysis = df_etab[['vel_id', 'finess_et', 'raison_sociale', 'departement']].copy()\n",
    "    \n",
    "    # Join Qualifications\n",
    "    # Note: score_satisfaction is no longer in Qualifications\n",
    "    df_analysis = df_analysis.merge(df_qual[['vel_id', 'niveau_certification', 'url_rapport']], \n",
    "                                    on='vel_id', how='left')\n",
    "    \n",
    "    # Join Metrics\n",
    "    df_analysis = df_analysis.merge(df_metrics[['vel_id', 'score_all_ssr_ajust', 'participation']], \n",
    "                                    on='vel_id', how='left')\n",
    "    \n",
    "    print(f\"Analysis Shape: {df_analysis.shape}\")\n",
    "    display(df_analysis[df_analysis['score_all_ssr_ajust'].notna()].head())\n",
    "else:\n",
    "    print(\"Dataframes not loaded.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
